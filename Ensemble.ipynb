{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data: Records of four top wide-receivers career games and their stats. This raw data was pulled from https://www.pro-football-reference.com/. \n",
    "\n",
    "Classification: How number of receiving yards and touchdowns per player predicts whether or not they won the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Yards  Touchdowns  Is Win\n",
      "0        0           0       1\n",
      "1       49           0       0\n",
      "2       81           0       0\n",
      "3       36           1       1\n",
      "4       93           1       1\n",
      "..     ...         ...     ...\n",
      "568    121           2       1\n",
      "569     31           2       1\n",
      "570     70           1       1\n",
      "571     26           0       1\n",
      "572     44           1       0\n",
      "\n",
      "[573 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('Football.csv')\n",
    "\n",
    "df['isWin'] = df['Result'].apply(lambda x: 1 if x.startswith('W') else 0)\n",
    "\n",
    "\n",
    "df_final = df[['Yds', 'TD', 'isWin']].dropna()\n",
    "df_final = df_final.rename(columns={'Yds': 'Yards', 'TD': 'Touchdowns', 'isWin': 'Is Win'})\n",
    "\n",
    "numRows = len(df_final)\n",
    "\n",
    "print(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_final.iloc[0:numRows, 2].values\n",
    "X = df_final.iloc[0:numRows, [0,1]].values\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=1, stratify=y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first pipeline standardizes features before applying logistic regression.\n",
    "The second pipeline applies a decision tree classifier directly.\n",
    "The third pipeline standardizes features before using a K-nearest neighbors classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold cross validation:\n",
      "\n",
      "Accuracy: 0.63 Stdev: 0.003 [LogisticRegression]\n",
      "Accuracy: 0.61 Stdev: 0.038 [Decision tree]\n",
      "Accuracy: 0.63 Stdev: 0.003 [SVM]\n",
      "Accuracy: 0.63 Stdev: 0.003 [Majority voting]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "pipe1 = make_pipeline(StandardScaler(), LogisticRegression(tol=.001, random_state=1))\n",
    "\n",
    "pipe2 = make_pipeline(DecisionTreeClassifier(max_depth=2,\n",
    "                                             criterion='entropy',\n",
    "                                             random_state=1))\n",
    "\n",
    "pipe3 = make_pipeline(StandardScaler(), SVC(kernel='linear', C=0.001, random_state=1))\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "mv_clf = VotingClassifier(estimators=[('lr', pipe1), ('dt', pipe2), ('svm', pipe3)])\n",
    "\n",
    "all_clf = [pipe1, pipe2, pipe3, mv_clf]\n",
    "\n",
    "clf_labels = ['LogisticRegression', 'Decision tree', 'SVM', 'Majority voting']\n",
    "\n",
    "print('10-fold cross validation:\\n')\n",
    "for clf, label in zip(all_clf, clf_labels):\n",
    "    scores = cross_val_score(estimator=clf,\n",
    "                             X=X_train,\n",
    "                             y=y_train,\n",
    "                             cv=10,\n",
    "                             scoring='accuracy')\n",
    "    print(\"Accuracy: \" + str(round(scores.mean(), 2)) + \n",
    "          \" Stdev: \" + str(round(scores.std(), 3)) +\n",
    "          \" [\" + label + \"]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 10-fold cross validation results show that both the Logistic Regression and SVM pipelines achieved an average accuracy of 0.63 with very low variability (Stdev: 0.003), while the Decision Tree pipeline obtained a slightly lower accuracy of 0.61 with higher variability (Stdev: 0.038).\n",
    "\n",
    "Majority Voting:\n",
    "\n",
    "The ensemble method combines the predictions of the individual models—Logistic Regression, Decision Tree, and SVM—by taking a vote on the predicted class for each sample. In majority voting, each model casts a vote, and the class that receives the most votes is selected as the final prediction. This approach can help balance out the weaknesses of individual models and often leads to a more robust overall prediction. In these results, the majority voting ensemble achieved an accuracy of 0.63 with low variability, aligning with the performance of the best individual models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified test set examples: 64\n",
      "Out of a total of: 172\n",
      "Accuracy: 0.627906976744186\n"
     ]
    }
   ],
   "source": [
    "pipe1.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe1.predict(X_test)\n",
    "print('Misclassified test set examples:', (y_test != y_pred).sum())\n",
    "print('Out of a total of:', y_test.shape[0])\n",
    "print('Accuracy:', pipe1.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)\n",
    "\n",
    "X_combined_std = np.vstack((X_train_std, X_test_std))\n",
    "y_combined = np.hstack((y_train, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified test set examples: 61\n",
      "Out of a total of: 172\n",
      "Accuracy: 0.6453488372093024\n"
     ]
    }
   ],
   "source": [
    "pipe2.fit(X_train, y_train)\n",
    "y_pred = pipe2.predict(X_test)\n",
    "print('Misclassified test set examples:', (y_test != y_pred).sum())\n",
    "print('Out of a total of:', y_test.shape[0])\n",
    "print('Accuracy:', pipe2.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified test set examples: 64\n",
      "Out of a total of: 172\n",
      "Accuracy: 0.627906976744186\n"
     ]
    }
   ],
   "source": [
    "pipe3.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe3.predict(X_test)\n",
    "print('Misclassified test set examples:', (y_test != y_pred).sum())\n",
    "print('Out of a total of:', y_test.shape[0])\n",
    "print('Accuracy:', pipe3.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified test set examples: 64\n",
      "Out of a total of: 172\n",
      "Accuracy: 0.627906976744186\n"
     ]
    }
   ],
   "source": [
    "mv_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = mv_clf.predict(X_test)\n",
    "print('Misclassified test set examples:', (y_test != y_pred).sum())\n",
    "print('Out of a total of:', y_test.shape[0])\n",
    "print('Accuracy:', mv_clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of the testing data mostly align with that of the cross-validation, but the decision tree does better than all the other models with the testing data. This is most likely just a coincidence of the testing data since it is not majorly outperforming the other models. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
