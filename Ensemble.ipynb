{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data: Records of four top wide-receivers career games and their stats. \n",
    "\n",
    "Classification: How number of receiving yards and touchdowns per player predicts whether or not the team won.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "isWin\n",
      "1    359\n",
      "0    214\n",
      "Name: count, dtype: int64\n",
      "Yards  Touchdowns  Is Win\n",
      "0      0           1         14\n",
      "                   0          8\n",
      "27     0           1          8\n",
      "74     0           1          5\n",
      "13     0           0          4\n",
      "                             ..\n",
      "64     2           1          1\n",
      "65     0           0          1\n",
      "                   1          1\n",
      "       2           1          1\n",
      "206    1           1          1\n",
      "Name: count, Length: 363, dtype: int64\n",
      "     Yards  Touchdowns  Is Win\n",
      "0        0           0       1\n",
      "1       49           0       0\n",
      "2       81           0       0\n",
      "3       36           1       1\n",
      "4       93           1       1\n",
      "..     ...         ...     ...\n",
      "568    121           2       1\n",
      "569     31           2       1\n",
      "570     70           1       1\n",
      "571     26           0       1\n",
      "572     44           1       0\n",
      "\n",
      "[573 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('Football.csv')\n",
    "\n",
    "df['isWin'] = df['Result'].apply(lambda x: 1 if x.startswith('W') else 0)\n",
    "\n",
    "\n",
    "df_final = df[['Yds', 'TD', 'isWin']].dropna()\n",
    "df_final = df_final.rename(columns={'Yds': 'Yards', 'TD': 'Touchdowns', 'isWin': 'Is Win'})\n",
    "\n",
    "numRows = len(df_final)\n",
    "\n",
    "print(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[105   0]\n",
      " [  0   0]\n",
      " [ 34   0]\n",
      " [ 90   1]\n",
      " [ 59   1]\n",
      " [179   1]\n",
      " [ 24   0]\n",
      " [ 34   0]\n",
      " [ 44   1]\n",
      " [ 44   1]\n",
      " [ 83   0]\n",
      " [ 88   0]\n",
      " [  9   0]\n",
      " [ 28   1]\n",
      " [135   1]\n",
      " [126   0]\n",
      " [ 55   0]\n",
      " [156   0]\n",
      " [ 22   0]\n",
      " [109   1]\n",
      " [ 42   0]\n",
      " [ 89   1]\n",
      " [ 43   0]\n",
      " [ 60   0]\n",
      " [ 59   0]\n",
      " [  7   0]\n",
      " [  0   0]\n",
      " [136   2]\n",
      " [ 45   0]\n",
      " [162   1]\n",
      " [115   2]\n",
      " [ 11   0]\n",
      " [ 33   0]\n",
      " [144   2]\n",
      " [ 98   0]\n",
      " [ 62   0]\n",
      " [110   0]\n",
      " [  0   0]\n",
      " [ 94   2]\n",
      " [106   1]\n",
      " [101   1]\n",
      " [ 40   0]\n",
      " [ 84   1]\n",
      " [ 32   1]\n",
      " [ 67   0]\n",
      " [167   0]\n",
      " [ 47   0]\n",
      " [  3   0]\n",
      " [ 84   0]\n",
      " [ 74   0]\n",
      " [ 74   0]\n",
      " [ 75   1]\n",
      " [  8   0]\n",
      " [ 49   0]\n",
      " [ 88   2]\n",
      " [ 42   0]\n",
      " [ 14   1]\n",
      " [180   0]\n",
      " [ 50   1]\n",
      " [141   1]\n",
      " [ 67   2]\n",
      " [116   1]\n",
      " [ 69   1]\n",
      " [ 54   0]\n",
      " [ 82   1]\n",
      " [ 31   0]\n",
      " [ 54   1]\n",
      " [112   0]\n",
      " [ 87   0]\n",
      " [ 73   0]\n",
      " [ 84   2]\n",
      " [  0   0]\n",
      " [ 46   0]\n",
      " [  6   0]\n",
      " [ 99   0]\n",
      " [ 42   0]\n",
      " [ 17   0]\n",
      " [ 94   2]\n",
      " [206   1]\n",
      " [111   1]\n",
      " [ 44   0]\n",
      " [ 69   1]\n",
      " [ 81   1]\n",
      " [ 26   0]\n",
      " [ 46   1]\n",
      " [ 21   1]\n",
      " [  0   0]\n",
      " [106   0]\n",
      " [ 53   3]\n",
      " [ 85   0]\n",
      " [ 23   0]\n",
      " [ 99   2]\n",
      " [ 18   0]\n",
      " [ 88   1]\n",
      " [136   1]\n",
      " [ 79   0]\n",
      " [121   0]\n",
      " [ 42   0]\n",
      " [ 41   0]\n",
      " [ 66   0]\n",
      " [151   0]\n",
      " [ 52   1]\n",
      " [ 28   0]\n",
      " [ 14   0]\n",
      " [  3   0]\n",
      " [ 89   0]\n",
      " [ 67   1]\n",
      " [ 34   0]\n",
      " [ 76   1]\n",
      " [ 75   0]\n",
      " [ 30   0]\n",
      " [106   0]\n",
      " [ 57   1]\n",
      " [ 20   0]\n",
      " [ 15   0]\n",
      " [ 28   0]\n",
      " [ 89   3]\n",
      " [127   1]\n",
      " [ 93   1]\n",
      " [ 77   1]\n",
      " [ 36   0]\n",
      " [ 85   1]\n",
      " [ 59   0]\n",
      " [ 88   2]\n",
      " [ 87   0]\n",
      " [113   0]\n",
      " [ 25   0]\n",
      " [ 47   0]\n",
      " [107   2]\n",
      " [ 47   1]\n",
      " [ 41   0]\n",
      " [  0   0]\n",
      " [100   0]\n",
      " [126   2]\n",
      " [ 93   1]\n",
      " [109   1]\n",
      " [ 46   0]\n",
      " [ 50   1]\n",
      " [ 52   1]\n",
      " [  0   0]\n",
      " [ 42   1]\n",
      " [ 35   0]\n",
      " [ 46   0]\n",
      " [136   2]\n",
      " [ 58   1]\n",
      " [ 57   1]\n",
      " [111   1]\n",
      " [132   1]\n",
      " [146   2]\n",
      " [ 58   0]\n",
      " [ 61   1]\n",
      " [ 12   1]\n",
      " [ 36   0]\n",
      " [ 92   1]\n",
      " [ 13   0]\n",
      " [ 37   1]\n",
      " [ 34   0]\n",
      " [ 90   1]\n",
      " [ 84   0]\n",
      " [ 61   0]\n",
      " [ 51   0]\n",
      " [ 12   0]\n",
      " [140   1]\n",
      " [116   0]\n",
      " [ 27   0]\n",
      " [ 13   0]\n",
      " [ 65   0]\n",
      " [ 60   0]\n",
      " [  0   0]\n",
      " [ 36   0]\n",
      " [156   2]\n",
      " [  6   0]\n",
      " [ 12   0]\n",
      " [ 68   0]\n",
      " [ 41   0]\n",
      " [ 67   0]\n",
      " [ 69   0]\n",
      " [ 43   1]\n",
      " [127   1]\n",
      " [ 66   2]\n",
      " [ 49   0]\n",
      " [ 35   0]\n",
      " [ 45   1]\n",
      " [100   1]\n",
      " [ 24   0]\n",
      " [  0   0]\n",
      " [ 53   2]\n",
      " [ 62   1]\n",
      " [ 30   0]\n",
      " [  0   0]\n",
      " [ 74   1]\n",
      " [ 72   0]\n",
      " [119   1]\n",
      " [ 85   2]\n",
      " [103   1]\n",
      " [ 10   0]\n",
      " [ 81   1]\n",
      " [ 35   0]\n",
      " [ 62   0]\n",
      " [ 44   1]\n",
      " [ 23   0]\n",
      " [ 13   1]\n",
      " [ 11   1]\n",
      " [ 44   1]\n",
      " [ 16   0]\n",
      " [108   0]\n",
      " [ 56   0]\n",
      " [132   2]\n",
      " [ 79   1]\n",
      " [ 22   1]\n",
      " [ 21   1]\n",
      " [ 77   0]\n",
      " [160   1]\n",
      " [172   2]\n",
      " [  8   0]\n",
      " [ 13   0]\n",
      " [136   1]\n",
      " [ 70   0]\n",
      " [ 22   0]\n",
      " [109   1]\n",
      " [ 81   3]\n",
      " [ 60   1]\n",
      " [ 26   0]\n",
      " [ 85   1]\n",
      " [ 33   0]\n",
      " [124   2]\n",
      " [ 62   0]\n",
      " [ 57   0]\n",
      " [ 21   0]\n",
      " [ 25   1]\n",
      " [ 45   0]\n",
      " [132   2]\n",
      " [ 84   0]\n",
      " [  6   0]\n",
      " [ 47   0]\n",
      " [ 44   2]\n",
      " [  0   0]\n",
      " [113   0]\n",
      " [ 10   0]\n",
      " [126   1]\n",
      " [142   0]\n",
      " [ 36   1]\n",
      " [ 37   0]\n",
      " [107   0]\n",
      " [ 33   1]\n",
      " [ 31   0]\n",
      " [ 93   1]\n",
      " [ 38   0]\n",
      " [ 69   1]\n",
      " [ 38   0]\n",
      " [ 68   1]\n",
      " [107   1]\n",
      " [134   1]\n",
      " [ 60   1]\n",
      " [ 54   0]\n",
      " [118   1]\n",
      " [ 12   0]\n",
      " [ 95   0]\n",
      " [131   1]\n",
      " [ 84   2]\n",
      " [ 94   2]\n",
      " [ 12   1]\n",
      " [ 89   1]\n",
      " [ 71   0]\n",
      " [ 89   0]\n",
      " [  5   0]\n",
      " [ 27   0]\n",
      " [106   2]\n",
      " [ 63   1]\n",
      " [ 27   0]\n",
      " [121   2]\n",
      " [ 73   1]\n",
      " [104   0]\n",
      " [ 26   0]\n",
      " [ 84   1]\n",
      " [ 44   0]\n",
      " [106   2]\n",
      " [101   0]\n",
      " [ 75   0]\n",
      " [124   2]\n",
      " [168   0]\n",
      " [ 49   0]\n",
      " [ 50   1]\n",
      " [111   1]\n",
      " [ 15   1]\n",
      " [ 60   0]\n",
      " [ 56   0]\n",
      " [ 82   1]\n",
      " [ 73   0]\n",
      " [ 71   1]\n",
      " [ 83   1]\n",
      " [ 78   1]\n",
      " [137   2]\n",
      " [ 18   1]\n",
      " [ 83   1]\n",
      " [113   0]\n",
      " [140   0]\n",
      " [  8   0]\n",
      " [  0   0]\n",
      " [ 42   2]\n",
      " [141   3]\n",
      " [ 56   0]\n",
      " [ 29   0]\n",
      " [104   0]\n",
      " [ 73   1]\n",
      " [ 63   1]\n",
      " [ 64   1]\n",
      " [ 11   0]\n",
      " [ 88   0]\n",
      " [ 89   0]\n",
      " [ 73   0]\n",
      " [ 57   1]\n",
      " [ 58   0]\n",
      " [ 32   0]\n",
      " [ 65   0]\n",
      " [ 89   1]\n",
      " [136   1]\n",
      " [ 41   1]\n",
      " [ 10   0]\n",
      " [121   2]\n",
      " [142   3]\n",
      " [ 17   0]\n",
      " [ 88   1]\n",
      " [ 90   0]\n",
      " [ 40   0]\n",
      " [ 66   0]\n",
      " [110   1]\n",
      " [ 31   0]\n",
      " [ 68   1]\n",
      " [ 63   0]\n",
      " [ 41   0]\n",
      " [121   2]\n",
      " [109   0]\n",
      " [ 43   0]\n",
      " [ 50   1]\n",
      " [ 13   0]\n",
      " [104   1]\n",
      " [109   1]\n",
      " [ 86   0]\n",
      " [196   2]\n",
      " [119   0]\n",
      " [ 15   0]\n",
      " [ 46   1]\n",
      " [ 92   1]\n",
      " [ 70   0]\n",
      " [133   1]\n",
      " [ 32   0]\n",
      " [ 73   0]\n",
      " [ 13   1]\n",
      " [ 24   0]\n",
      " [  0   0]\n",
      " [ 59   1]\n",
      " [ 58   0]\n",
      " [ 74   0]\n",
      " [ 83   0]\n",
      " [ 27   0]\n",
      " [ 51   0]\n",
      " [ 66   1]\n",
      " [ 70   1]\n",
      " [115   2]\n",
      " [ 45   1]\n",
      " [ 45   0]\n",
      " [ 78   0]\n",
      " [ 57   0]\n",
      " [ 88   1]\n",
      " [ 37   0]\n",
      " [ 53   0]\n",
      " [ 34   1]\n",
      " [ 31   0]\n",
      " [ 19   0]\n",
      " [ 30   0]\n",
      " [101   0]\n",
      " [ 51   2]\n",
      " [ 34   0]\n",
      " [ 80   0]\n",
      " [ 13   0]\n",
      " [ 27   1]\n",
      " [  8   0]\n",
      " [  0   0]\n",
      " [ 44   0]\n",
      " [ 91   1]\n",
      " [ 42   0]\n",
      " [ 19   0]\n",
      " [166   0]\n",
      " [ 82   0]\n",
      " [  0   0]\n",
      " [ 76   2]\n",
      " [115   0]\n",
      " [ 81   1]\n",
      " [ 70   0]\n",
      " [  1   0]\n",
      " [116   1]\n",
      " [127   1]\n",
      " [  0   0]\n",
      " [ 67   1]\n",
      " [124   2]\n",
      " [ 69   1]\n",
      " [ 23   1]\n",
      " [ 79   1]\n",
      " [  0   0]\n",
      " [ 50   0]]\n"
     ]
    }
   ],
   "source": [
    "y = df_final.iloc[0:numRows, 2].values\n",
    "X = df_final.iloc[0:numRows, [0,1]].values\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=1, stratify=y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first pipeline standardizes features before applying logistic regression.\n",
    "The second pipeline applies a decision tree classifier directly.\n",
    "The third pipeline standardizes features before using a K-nearest neighbors classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold cross validation:\n",
      "\n",
      "Accuracy: 0.63 Stdev: 0.003 [LogisticRegression]\n",
      "Accuracy: 0.61 Stdev: 0.038 [Decision tree]\n",
      "Accuracy: 0.63 Stdev: 0.003 [SVM]\n",
      "Accuracy: 0.63 Stdev: 0.003 [Majority voting]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "pipe1 = make_pipeline(StandardScaler(), LogisticRegression(tol=.001, random_state=1))\n",
    "\n",
    "pipe2 = make_pipeline(DecisionTreeClassifier(max_depth=2,\n",
    "                                             criterion='entropy',\n",
    "                                             random_state=1))\n",
    "\n",
    "pipe3 = make_pipeline(StandardScaler(), SVC(kernel='linear', C=0.001, random_state=1))\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "mv_clf = VotingClassifier(estimators=[('lr', pipe1), ('dt', pipe2), ('svm', pipe3)])\n",
    "\n",
    "all_clf = [pipe1, pipe2, pipe3, mv_clf]\n",
    "\n",
    "clf_labels = ['LogisticRegression', 'Decision tree', 'SVM', 'Majority voting']\n",
    "\n",
    "print('10-fold cross validation:\\n')\n",
    "for clf, label in zip(all_clf, clf_labels):\n",
    "    scores = cross_val_score(estimator=clf,\n",
    "                             X=X_train,\n",
    "                             y=y_train,\n",
    "                             cv=10,\n",
    "                             scoring='accuracy')\n",
    "    print(\"Accuracy: \" + str(round(scores.mean(), 2)) + \n",
    "          \" Stdev: \" + str(round(scores.std(), 3)) +\n",
    "          \" [\" + label + \"]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 10-fold cross validation results show that both the Logistic Regression and SVM pipelines achieved an average accuracy of 0.63 with very low variability (Stdev: 0.003), while the Decision Tree pipeline obtained a slightly lower accuracy of 0.61 with higher variability (Stdev: 0.038).\n",
    "\n",
    "Majority Voting:\n",
    "\n",
    "The ensemble method combines the predictions of the individual models—Logistic Regression, Decision Tree, and SVM—by taking a vote on the predicted class for each sample. In majority voting, each model casts a vote, and the class that receives the most votes is selected as the final prediction. This approach can help balance out the weaknesses of individual models and often leads to a more robust overall prediction. In these results, the majority voting ensemble achieved an accuracy of 0.63 with low variability, aligning with the performance of the best individual models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified test set examples: 64\n",
      "Out of a total of: 172\n",
      "Accuracy: 0.627906976744186\n"
     ]
    }
   ],
   "source": [
    "pipe1.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe1.predict(X_test)\n",
    "print('Misclassified test set examples:', (y_test != y_pred).sum())\n",
    "print('Out of a total of:', y_test.shape[0])\n",
    "print('Accuracy:', pipe1.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)\n",
    "\n",
    "X_combined_std = np.vstack((X_train_std, X_test_std))\n",
    "y_combined = np.hstack((y_train, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified test set examples: 61\n",
      "Out of a total of: 172\n",
      "Accuracy: 0.6453488372093024\n"
     ]
    }
   ],
   "source": [
    "pipe2.fit(X_train, y_train)\n",
    "y_pred = pipe2.predict(X_test)\n",
    "print('Misclassified test set examples:', (y_test != y_pred).sum())\n",
    "print('Out of a total of:', y_test.shape[0])\n",
    "print('Accuracy:', pipe2.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified test set examples: 64\n",
      "Out of a total of: 172\n",
      "Accuracy: 0.627906976744186\n"
     ]
    }
   ],
   "source": [
    "pipe3.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe3.predict(X_test)\n",
    "print('Misclassified test set examples:', (y_test != y_pred).sum())\n",
    "print('Out of a total of:', y_test.shape[0])\n",
    "print('Accuracy:', pipe3.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified test set examples: 64\n",
      "Out of a total of: 172\n",
      "Accuracy: 0.627906976744186\n"
     ]
    }
   ],
   "source": [
    "mv_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = mv_clf.predict(X_test)\n",
    "print('Misclassified test set examples:', (y_test != y_pred).sum())\n",
    "print('Out of a total of:', y_test.shape[0])\n",
    "print('Accuracy:', mv_clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of the testing data mostly align with that of the cross-validation, but the decision tree does better than all the other models with the testing data. This is most likely just a coincidence of the testing data since it is not majorly outperforming the other models. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
